# ğŸ¤– Online kurz: StrojovÃ© uÄenie (Machine Learning) v Pythone so scikit-learn

> PraktickÃ½ kurz pre zaÄiatoÄnÃ­kov â€“ Regresia v ML, scikit-learn, modelovanie, trÃ©ning a vyhodnocovanie

---

## ğŸ“˜ Obsah kurzu

01. [**ğŸ” Ãšvod do strojovÃ©ho uÄenia a regresie**](#uvod-ml-regresia)
01. [**ğŸ“¦ HlavnÃ© datasety v sklearn.datasets**](#prehlad-datasety) 
01. [**ğŸ§  PrehÄ¾ad typov regresii**](#prehlad-typov-regresii)
01. [**ğŸ“ RegresnÃ© rovnice v strojovom uÄenÃ­**](#regresne-rovnice)
01. [**ğŸ“ˆ LineÃ¡rna regresia v scikit-learn**](#linearna-regresia)  
01. [**ğŸ§® ViacnÃ¡sobnÃ¡ regresia a vÃ½ber parametrov**](#viacnasobna-regresia)  
01. [**ğŸ“š Zdroje a literatÃºra k strojovemu uceniu a scikit-learn**](#zdroje-a-literatura)  
01. [**âœ… OdporÃºÄania ML, regresia a Scikit-Learn**](#odporucania)

---

<a name="uvod-ml-regresia"></a>
## ğŸ” 1. Ãšvod do strojovÃ©ho uÄenia a regresie

V tejto Ãºvodnej Äasti sa zoznÃ¡mime so zÃ¡kladnÃ½mi pojmami, rozdielmi medzi typmi ML Ãºloh, kniÅ¾nicou scikit-learn a jednoduchÃ½mi praktickÃ½mi prÃ­kladmi.

### ğŸ¯ ZÃ¡kladnÃ© pojmy

- **Supervised learning (uÄenie s uÄiteÄ¾om)** â€“ algoritmus sa uÄÃ­ na zÃ¡klade oznaÄenÃ½ch dÃ¡t (X vstupy, y vÃ½stupy)
- **Training (trÃ©ning)** â€“ fÃ¡za uÄenia modelu na zÃ¡klade historickÃ½ch Ãºdajov
- **Testing (testovanie)** â€“ overenie vÃ½konu modelu na novÃ½ch Ãºdajoch, ktorÃ© nevidel
- **Regresia vs. klasifikÃ¡cia**:
  - *Regresia* predpovedÃ¡ **spojitÃ© hodnoty** (napr. cena, teplota)
  - *KlasifikÃ¡cia* predpovedÃ¡ **kategÃ³rie** (napr. Ã¡no/nie, trieda A/B/C)

### ğŸ§© Typy regresiÃ­ (prehÄ¾ad)

- **JednoduchÃ¡ lineÃ¡rna regresia** â€“ 1 vstupnÃ¡ premennÃ¡ (napr. vÃ½Å¡ka â†’ hmotnosÅ¥)
- **ViacnÃ¡sobnÃ¡ lineÃ¡rna regresia** â€“ viac vstupov (napr. vÃ½Å¡ka, vek, BMI â†’ hmotnosÅ¥)
- **PolynomiÃ¡lna regresia** â€“ rozÅ¡Ã­renie lineÃ¡rnej pomocou nelineÃ¡rnych zloÅ¾iek

---

### ğŸ§ª PrÃ­klad 1: NaÄÃ­tanie dÃ¡t a zÃ¡kladnÃ¡ Å¡tatistika

```python
from sklearn.datasets import load_diabetes
import pandas as pd

# NaÄÃ­tanie datasetu (zabudovanÃ½ dataset s Ãºdajmi o cukrovke)
data = load_diabetes(as_frame=True)
df = data.frame

# Zobrazenie prvÃ½ch 5 riadkov
print(df.head())

# ZÃ¡kladnÃ¡ Å¡tatistika
print(df.describe())
```

---

### ğŸ§ª PrÃ­klad 2: Rozdelenie dÃ¡t na trÃ©ningovÃº a testovaciu mnoÅ¾inu

```python
from sklearn.model_selection import train_test_split

X = df.drop(columns='target')  # vstupy (atribÃºty)
y = df['target']               # cieÄ¾ovÃ¡ premennÃ¡

# Rozdelenie na 80 % trÃ©ning a 20 % test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("TrÃ©ningovÃ¡ mnoÅ¾ina:", X_train.shape)
print("Testovacia mnoÅ¾ina:", X_test.shape)
```

---

### ğŸ§ª PrÃ­klad 3: ZÃ¡kladnÃ¡ vizualizÃ¡cia vzÅ¥ahu medzi atribÃºtom a cieÄ¾om

```python
import matplotlib.pyplot as plt

# Porovnanie BMI a cieÄ¾ovej hodnoty
plt.scatter(X['bmi'], y, color='green', alpha=0.5)
plt.xlabel('BMI')
plt.ylabel('CieÄ¾ovÃ¡ premennÃ¡ (target)')
plt.title('VzÅ¥ah medzi BMI a cieÄ¾om')
plt.grid(True)
plt.show()
```

---

### ğŸ§ª PrÃ­klad 4: PrehÄ¾ad funkciÃ­ kniÅ¾nice scikit-learn

```python
import sklearn
#sklearn.show_versions()

# Verzia kniÅ¾nice
print("scikit-learn verzia:", sklearn.__version__)

# Skontroluj dostupnÃ© moduly: linear_model, model_selection, metrics...
from sklearn import linear_model, metrics, preprocessing
print(dir(sklearn))
print(dir(linear_model))  # dostupnÃ© modely v linear_model
```

### ğŸ§© PrehÄ¾ad hlavnÃ½ch modulov scikit-learn s kategorizÃ¡ciou

| Modul                  | Popis                                                                 | PrÃ­klad pouÅ¾itia                                 | KategÃ³ria                        |
|------------------------|-----------------------------------------------------------------------|--------------------------------------------------|----------------------------------|
| `datasets`             | VstavanÃ© datasety a generovanie syntetickÃ½ch Ãºdajov                   | `load_iris()`, `make_classification()`           | ZÃ¡kladnÃ½ modul                   |
| `model_selection`      | Rozdelenie dÃ¡t, validÃ¡cia, ladenie parametrov                         | `train_test_split()`, `GridSearchCV()`           | ZÃ¡kladnÃ½ modul                   |
| `metrics`              | Metriky pre hodnotenie modelov                                       | `accuracy_score()`, `r2_score()`                 | ZÃ¡kladnÃ½ modul                   |
| `linear_model`         | LineÃ¡rna a logistickÃ¡ regresia                                        | `LinearRegression()`, `LogisticRegression()`     | ZÃ¡kladnÃ½ modul                   |
| `tree`                 | Rozhodovacie stromy                                                   | `DecisionTreeClassifier()`                       | ZÃ¡kladnÃ½ modul                   |
| `ensemble`             | ZloÅ¾enÃ© modely (RandomForest, Boosting...)                            | `RandomForestClassifier()`                       | ZÃ¡kladnÃ½ modul                   |
| `svm`                  | Support Vector Machines                                               | `SVC()`, `SVR()`                                 | ZÃ¡kladnÃ½ modul                   |
| `neighbors`            | NajbliÅ¾Å¡Ã­ susedia                                                     | `KNeighborsClassifier()`                         | ZÃ¡kladnÃ½ modul                   |
| `naive_bayes`          | NaÃ­vne Bayesove klasifikÃ¡tory                                         | `GaussianNB()`                                   | ZÃ¡kladnÃ½ modul                   |
| `neural_network`       | ViacvrstvovÃ© neurÃ³novÃ© siete                                          | `MLPClassifier()`, `MLPRegressor()`              | ZÃ¡kladnÃ½ modul                   |
| `preprocessing`        | Ãšprava dÃ¡t: Å¡kÃ¡lovanie, normalizÃ¡cia, kÃ³dovanie                       | `StandardScaler()`, `OneHotEncoder()`            | ZÃ¡kladnÃ½ modul                   |
| `impute`               | DoplÅˆovanie chÃ½bajÃºcich hodnÃ´t                                       | `SimpleImputer()`, `KNNImputer()`                | ZÃ¡kladnÃ½ modul                   |
| `pipeline`             | ZreÅ¥azenie krokov (transformÃ¡cie + model)                             | `Pipeline([...])`                                | ZÃ¡kladnÃ½ modul                   |
| `feature_selection`    | VÃ½ber najdÃ´leÅ¾itejÅ¡Ã­ch vlastnostÃ­                                     | `SelectKBest()`, `RFE()`                         | ZÃ¡kladnÃ½ modul                   |
| `feature_extraction`   | Extrakcia znakov z textu, obrÃ¡zkov                                    | `CountVectorizer()`, `TfidfTransformer()`        | ZÃ¡kladnÃ½ modul                   |
| `decomposition`        | Redukcia dimenzie (napr. PCA)                                         | `PCA()`, `TruncatedSVD()`                        | PokroÄilejÅ¡Ã­ modul              |
| `manifold`             | NelineÃ¡rna redukcia dimenzie                                          | `TSNE()`, `Isomap()`                             | PokroÄilejÅ¡Ã­ modul              |
| `cluster`              | Klastrovanie bez dozorovania                                          | `KMeans()`, `DBSCAN()`                           | PokroÄilejÅ¡Ã­ modul              |
| `mixture`              | ZmesovÃ© modely (pravdepodobnostnÃ© klastrovanie)                      | `GaussianMixture()`                              | PokroÄilejÅ¡Ã­ modul              |
| `discriminant_analysis`| LDA a QDA pre viac tried                                              | `LinearDiscriminantAnalysis()`                   | PokroÄilejÅ¡Ã­ modul              |
| `multiclass`           | RozÅ¡Ã­renia pre viac ako 2 tried                                       | `OneVsRestClassifier()`                          | PokroÄilejÅ¡Ã­ modul              |
| `multioutput`          | Modely s viacerÃ½mi vÃ½stupmi                                           | `MultiOutputClassifier()`                        | PokroÄilejÅ¡Ã­ modul              |
| `experimental`         | Funkcie v experimentÃ¡lnom stave                                       | `HistGradientBoostingClassifier()`               | ExperimentÃ¡lny modul            |
| `inspection`           | InterpretÃ¡cia modelov                                                 | `permutation_importance()`                       | PokroÄilejÅ¡Ã­ modul              |
| `compose`              | Kombinovanie transformÃ¡ciÃ­                                            | `ColumnTransformer()`                            | PokroÄilejÅ¡Ã­ modul              |
| `random_projection`    | Redukcia dimenzie nÃ¡hodnou projekciou                                | `GaussianRandomProjection()`                     | PokroÄilejÅ¡Ã­ modul              |
| `gaussian_process`     | Modely zaloÅ¾enÃ© na GaussovÃ½ch procesoch                               | `GaussianProcessRegressor()`                     | PokroÄilejÅ¡Ã­ modul              |
| `isotonic`             | IzotonickÃ¡ (monotÃ³nna) regresia                                       | `IsotonicRegression()`                           | PokroÄilejÅ¡Ã­ modul              |
| `kernel_approximation` | PribliÅ¾nÃ© jadrovÃ© transformÃ¡cie                                       | `RBFSampler()`                                   | PokroÄilejÅ¡Ã­ modul              |
| `kernel_ridge`         | KombinÃ¡cia ridge a kernel metÃ³d                                      | `KernelRidge()`                                  | PokroÄilejÅ¡Ã­ modul              |
| `externals`            | InternÃ© zÃ¡vislosti (napr. `joblib`)                                   | â€“                                                | PodpornÃ½ modul                  |
| `exceptions`           | DefinÃ­cie chÃ½b a vÃ½nimiek                                             | â€“                                                | PodpornÃ½ modul                  |
| `get_config`           | ZÃ­skanie globÃ¡lnej konfigurÃ¡cie                                       | `get_config()`                                   | KonfigurÃ¡cia a nÃ¡stroje         |
| `set_config`           | Nastavenie globÃ¡lnej konfigurÃ¡cie                                     | `set_config(display='diagram')`                  | KonfigurÃ¡cia a nÃ¡stroje         |
| `config_context`       | DoÄasnÃ¡ zmena konfigurÃ¡cie                                            | `with config_context():`                         | KonfigurÃ¡cia a nÃ¡stroje         |
| `show_versions`        | VÃ½pis verziÃ­ kniÅ¾nice a zÃ¡vislostÃ­                                    | `show_versions()`                                | KonfigurÃ¡cia a nÃ¡stroje         |
| `clone`                | KopÃ­rovanie modelov                                                   | `clone(model)`                                   | KonfigurÃ¡cia a nÃ¡stroje         |


```python
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
import pandas as pd

# NaÄÃ­tanie vstupnÃ©ho datasetu diabetes
X, y = load_diabetes(return_X_y=True, as_frame=True)

# Rozdelenie na trÃ©ningovÃº a testovaciu mnoÅ¾inu (80:20)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# VÃ½pis tvaru datasetu
print(X_train.shape, X_test.shape)
```

---
<a name="prehlad-datasety"></a>
## ğŸ“¦ 2. HlavnÃ© datasety v `sklearn.datasets`

> PrehÄ¾ad zabudovanÃ½ch datasetov v kniÅ¾nici `scikit-learn`, rozdelenÃ½ podÄ¾a typu Ãºloh.

### ğŸ“¦ KlasifikaÄnÃ© datasety (pre Ãºlohy rozpoznÃ¡vania kategÃ³riÃ­)

| Dataset | Popis |
|--------|-------|
| `load_iris()` | ğŸª» Iris â€“ klasifikÃ¡cia druhov kvetov na zÃ¡klade rozmerov okvetia. |
| `load_digits()` | ğŸ”¢ Rukou pÃ­sanÃ© ÄÃ­slice (0â€“9) â€“ obrÃ¡zky 8x8 pixelov. |
| `load_wine()` | ğŸ· ChemickÃ© vlastnosti vÃ­n â€“ rozpoznanie odrody. |
| `load_breast_cancer()` | ğŸ§ª DÃ¡ta o nÃ¡doroch prsnÃ­ka â€“ klasifikÃ¡cia malÃ­gnych a benÃ­gnych. |
| `fetch_20newsgroups()` | ğŸ“° TextovÃ© dÃ¡ta z 20 kategÃ³riÃ­ diskusnÃ½ch skupÃ­n. |
| `fetch_20newsgroups_vectorized()` | ğŸ”¤ PredspracovanÃ¡ verzia predchÃ¡dzajÃºceho. |
| `fetch_covtype()` | ğŸŒ² LesnÃ© krytie â€“ predikcia typu vegetÃ¡cie na zÃ¡klade geografickÃ½ch znakov. |
| `fetch_kddcup99()` | ğŸŒ SieÅ¥ovÃ½ traffic â€“ detekcia anomÃ¡liÃ­ a Ãºtokov. |
| `fetch_lfw_people()` | ğŸ‘¤ RozpoznÃ¡vanie osÃ´b na obrÃ¡zkoch (LFW). |
| `fetch_lfw_pairs()` | ğŸ‘¥ PorovnÃ¡vanie tvÃ¡rÃ­ â€“ sÃº na dvoch obrÃ¡zkoch rovnakÃ© osoby? |
| `fetch_olivetti_faces()` | ğŸ§‘â€ğŸ¦± Dataset tvÃ¡rÃ­ â€“ rozpoznÃ¡vanie identÃ­t. |
| `fetch_rcv1()` | ğŸ“° Reuters texty â€“ multilabel klasifikÃ¡cia tÃ©m. |

### ğŸ“ˆ RegresnÃ© datasety

| Dataset | Popis |
|--------|-------|
| `load_diabetes()` | ğŸ§¬ Diabetes â€“ predikcia progresie choroby. |
| `fetch_california_housing()` | ğŸ˜ï¸ Predikcia cien nehnuteÄ¾nostÃ­ v Kalifornii. |

### ğŸ’ª InÃ© a Å¡peciÃ¡lne datasety

| Dataset | Popis |
|--------|-------|
| `load_linnerud()` | ğŸƒâ€â™‚ï¸ FyzickÃ© vÃ½kony a fyziologickÃ© dÃ¡ta. |
| `fetch_species_distributions()` | ğŸ¦ VÃ½skyt druhov podÄ¾a geografie. |
| `load_files()` | ğŸ“‚ NaÄÃ­tanie vlastnÃ½ch textovÃ½ch datasetov. |

### ğŸ–¼ï¸ Datasety s obrÃ¡zkami

| Dataset | Popis |
|--------|-------|
| `load_sample_image()` | ğŸ–¼ï¸ JednotlivÃ½ ukÃ¡Å¾kovÃ½ obrÃ¡zok (napr. ÄÃ­nska zÃ¡hrada). |
| `load_sample_images()` | ğŸ§© SÃºbor ukÃ¡Å¾kovÃ½ch obrÃ¡zkov. |

### âš™ï¸ Utility a nÃ¡stroje

| Funkcia | Popis |
|--------|-------|
| `clear_data_home()` | ğŸ§¹ VymaÅ¾e cache dÃ¡t scikit-learn. |
| `get_data_home()` | ğŸ“ ZÃ­ska cestu k dÃ¡tovej zloÅ¾ke. |
| `fetch_openml()` | ğŸŒ NaÄÃ­tanie datasetov z OpenML. |
| `fetch_file()` | ğŸ“¥ Stiahne sÃºbor z webu do cache. |
| `load_svmlight_file()` | ğŸ“„ NaÄÃ­tanie SVMlight/libSVM formÃ¡tu. |
| `load_svmlight_files()` | ğŸ“„ Viacero SVMlight sÃºborov. |
| `dump_svmlight_file()` | ğŸ’¾ Export dÃ¡t do SVMlight. |

> Viac info: [sklearn.datasets API](https://scikit-learn.org/stable/api/sklearn.datasets.html#module-sklearn.datasets)

<a name="prehlad-typov-regresii"></a>
## ğŸ§  3. PrehÄ¾ad typov regresiÃ­

RegresnÃ© modely sÃº urÄenÃ© na predpovedanie spojitÃ½ch hodnÃ´t. V tejto kapitole si predstavÃ­me zÃ¡kladnÃ© typy regresiÃ­, ich vÃ½hody, nevÃ½hody a ukÃ¡Å¾eme si jednoduchÃ© prÃ­klady.

### ğŸ“Š Typy regresie:

| Typ regresie               | Popis | PrÃ­klad pouÅ¾itia |
|----------------------------|-------|------------------|
| JednoduchÃ¡ lineÃ¡rna       | 1 vstupnÃ¡ premennÃ¡, lineÃ¡rny vzÅ¥ah | vÃ½Å¡ka â†’ hmotnosÅ¥ |
| ViacnÃ¡sobnÃ¡ lineÃ¡rna      | Viac vstupnÃ½ch premennÃ½ch | vek, BMI, prÃ­jem â†’ krvnÃ½ tlak |
| PolynomiÃ¡lna regresia     | Obsahuje nelineÃ¡rne Äleny (xÂ², xÂ³, ...) | vekÂ² â†’ vÃ½davky |
| Ridge regresia            | LineÃ¡rna regresia s L2 regularizÃ¡ciou | vysokodimenzionÃ¡lne dÃ¡ta |
| Lasso regresia            | LineÃ¡rna s L1 regularizÃ¡ciou (vÃ½ber premennÃ½ch) | selekcia atribÃºtov |
| ElasticNet                | KombinÃ¡cia L1 a L2 | kompromis medzi Ridge a Lasso |
| LogaritmickÃ¡ regresia     | ZaloÅ¾enÃ¡ na logaritmickej transformÃ¡cii | vÃ½skyt udalostÃ­ |
| RobustnÃ¡ regresia         | OdolnÃ¡ voÄi extrÃ©mnym hodnotÃ¡m (outlierom) | analÃ½za miezd |

---

### ğŸ§ª PrÃ­klad: PolynomiÃ¡lna regresia

```python
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline
from sklearn.linear_model import LinearRegression

# PouÅ¾Ã­vame len jeden atribÃºt pre prehÄ¾adnosÅ¥
X_poly = X_train[['bmi']]
y_poly = y_train

# Vytvorenie modelu s polynÃ³mom 2. stupÅˆa
poly_model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())
poly_model.fit(X_poly, y_poly)

# Predikcia
X_test_poly = X_test[['bmi']]
y_pred_poly = poly_model.predict(X_test_poly)
```

---

### ğŸ§ª PrÃ­klad: Ridge a Lasso regresia

```python
from sklearn.linear_model import Ridge, Lasso

# Ridge (L2 regularizÃ¡cia)
ridge_model = Ridge(alpha=1.0)
ridge_model.fit(X_train, y_train)
print("Ridge R2:", ridge_model.score(X_test, y_test))

# Lasso (L1 regularizÃ¡cia)
lasso_model = Lasso(alpha=0.1)
lasso_model.fit(X_train, y_train)
print("Lasso R2:", lasso_model.score(X_test, y_test))
```

â¡ï¸ KaÅ¾dÃ½ regresnÃ½ model sa hodÃ­ na inÃ½ typ Ãºlohy a dÃ¡ta. DÃ´leÅ¾itÃ© je analyzovaÅ¥:
- linearitu vzÅ¥ahu medzi premennÃ½mi,
- poÄet a korelÃ¡ciu vstupov,
- prÃ­tomnosÅ¥ extrÃ©mnych hodnÃ´t,
- a poÅ¾iadavky na interpretÃ¡ciu vs. vÃ½kon.


<a name="regresne-rovnice"></a>
## ğŸ“ 4. RegresnÃ© rovnice v strojovom uÄenÃ­

### 1ï¸âƒ£ LineÃ¡rna regresia (Simple Linear Regression)
**Rovnica:**  
`y = Î²â‚€ + Î²â‚Â·x + Îµ`

- `y` â€“ predikovanÃ¡ hodnota (napr. cena)
- `x` â€“ nezÃ¡vislÃ¡ premennÃ¡ (napr. rozloha)
- `Î²â‚€` â€“ intercept (konÅ¡tanta, keÄ x = 0)
- `Î²â‚` â€“ koeficient sklonu (ako rÃ½chlo y rastie s x)
- `Îµ` â€“ chyba modelu (residuum)

âœ” PrÃ­klad: Predikcia ceny domu na zÃ¡klade vÃ½mery.  
âœ” PrÃ­klad: Odhad spotreby energie podÄ¾a vonkajÅ¡ej teploty.

### 2ï¸âƒ£ ViacnÃ¡sobnÃ¡ lineÃ¡rna regresia (Multiple Linear Regression)
**Rovnica:**  
`y = Î²â‚€ + Î²â‚Â·xâ‚ + Î²â‚‚Â·xâ‚‚ + ... + Î²â‚™Â·xâ‚™ + Îµ`

- PouÅ¾Ã­va viacero vstupnÃ½ch premennÃ½ch (napr. prÃ­jem, lokalita, vek budovy)
- Koeficienty `Î²â‚...Î²â‚™` vyjadrujÃº vÃ½znam kaÅ¾dÃ©ho vstupu

âœ” PrÃ­klad: Predikcia ceny auta podÄ¾a veku, znaÄky, vÃ½konu a najazdenÃ½ch km.  
âœ” PrÃ­klad: Odhad vÃ½sledkov Å¡tudenta podÄ¾a dochÃ¡dzky, Äasu uÄenia a spÃ¡nku.

### 3ï¸âƒ£ PolynomiÃ¡lna regresia (Polynomial Regression)
**Rovnica:**  
`y = Î²â‚€ + Î²â‚Â·x + Î²â‚‚Â·xÂ² + ... + Î²â‚™Â·xâ¿ + Îµ`

- RozÅ¡iruje lineÃ¡rnu regresiu o vyÅ¡Å¡ie mocniny `x`
- Modeluje nelineÃ¡rne zÃ¡vislosti

âœ” PrÃ­klad: Predikcia vÃ½Å¡ky rastliny v zÃ¡vislosti od Äasu (krivka rastu).  
âœ” PrÃ­klad: Odhad vÃ½Å¡ky skoku v zÃ¡vislosti od rÃ½chlosti a uhla odrazu.

### 4ï¸âƒ£ Ridge regresia (L2 regularizÃ¡cia)
**Rovnica:**  
`minimize: ||y - XÎ²||Â² + Î»Â·||Î²||Â²`

- Penalizuje veÄ¾kÃ© koeficienty pomocou L2 normy
- PomÃ¡ha pri multikolinearite a zniÅ¾uje pretrÃ©novanie

âœ” VhodnÃ¡ ak mÃ¡te mnoho podobnÃ½ch vstupnÃ½ch premennÃ½ch.  
âœ” PrÃ­klad: Predikcia nÃ¡kladov na marketing z desiatok prepojenÃ½ch metrÃ­k.

### 5ï¸âƒ£ Lasso regresia (L1 regularizÃ¡cia)
**Rovnica:**  
`minimize: ||y - XÎ²||Â² + Î»Â·|Î²|`

- Penalizuje sÃºÄet absolÃºtnych hodnÃ´t koeficientov
- PomÃ¡ha automaticky vyberaÅ¥ dÃ´leÅ¾itÃ© premennÃ© (niektorÃ© Î² = 0)

âœ” UÅ¾itoÄnÃ© pri veÄ¾kom poÄte premennÃ½ch a potrebe vÃ½beru.  
âœ” PrÃ­klad: VÃ½ber najvplyvnejÅ¡Ã­ch faktorov ovplyvÅˆujÃºcich cenu nehnuteÄ¾nosti.

### 6ï¸âƒ£ Elastic Net
**Rovnica:**  
`minimize: ||y - XÎ²||Â² + Î»â‚Â·|Î²| + Î»â‚‚Â·||Î²||Â²`

- KombinÃ¡cia Ridge a Lasso
- LepÅ¡ia stabilita pri vysoko korelovanÃ½ch premennÃ½ch

âœ” ZvyÄajne sa nastavujÃº vÃ¡hy (Î±, Î») cez cross-validation.  
âœ” PrÃ­klad: Predikcia predaja produktov pri vysoko zÃ¡vislÃ½ch marketingovÃ½ch faktoroch.

### 7ï¸âƒ£ LogaritmickÃ¡ regresia (pre log-transformed y)
**Rovnica:**  
`ln(y) = Î²â‚€ + Î²â‚Â·x + Îµ`

- PouÅ¾Ã­va sa ak cieÄ¾ovÃ¡ premennÃ¡ mÃ¡ exponenciÃ¡lne rozdelenie
- VÃ½stup sa Äasto exponuje spÃ¤Å¥: `y = e^(predikcia)`

âœ” PrÃ­klad: Predikcia populÃ¡cie alebo ceny pri log-normÃ¡lnom rozdelenÃ­.  
âœ” PrÃ­klad: Odhad rastu pouÅ¾Ã­vateÄ¾ov novej aplikÃ¡cie.

### 8ï¸âƒ£ Regresia pomocou rozhodovacÃ­ch stromov
**PrincÃ­p:**  
Nie je zaloÅ¾enÃ¡ na rovniciach, ale na rekurzÃ­vnom delenÃ­:

```python
if xâ‚ < 2.5: predikcia = 100
elif xâ‚‚ > 5: predikcia = 200
```

âœ” VÃ½hoda: nepotrebuje Å¡kÃ¡lovanie dÃ¡t ani lineÃ¡rne vzÅ¥ahy.  
âœ” PrÃ­klad: Predikcia vÃ½davkov domÃ¡cnosti na zÃ¡klade segmentÃ¡cie podÄ¾a veku a prÃ­jmu.

### 9ï¸âƒ£ Support Vector Regression (SVR)
**PrincÃ­p:**  
NÃ¡jsÅ¥ funkciu `f(x)`, ktorÃ¡ sa lÃ­Å¡i od `y` o maximÃ¡lne `Îµ` a je Äo najplochÅ¡ia.

- UmoÅ¾Åˆuje nelineÃ¡rne vzÅ¥ahy pomocou kernelov (napr. RBF)
- Funguje dobre aj pri vysokorozmernÃ½ch dÃ¡tach

âœ” PrÃ­klad: Predikcia cien akciÃ­ s vyuÅ¾itÃ­m RBF kernelu.  
âœ” PrÃ­klad: OdhaÄ¾ovanie trendov v meteorologickÃ½ch dÃ¡tach.

### ğŸ”Ÿ K-nearest neighbors regresia (KNN Regression)
**Rovnica:**  
`y_pred = priemer(y susedov)`

- Predikcia = priemer vÃ½stupov najbliÅ¾Å¡Ã­ch `K` bodov
- Funguje na zÃ¡klade vzdialenosti medzi dÃ¡tami

âœ” NeparametrickÃ½, jednoduchÃ½ model.  
âœ” PrÃ­klad: Odhad ceny Airbnb na zÃ¡klade okolitÃ½ch ponÃºk.  
âœ” PrÃ­klad: Predikcia Äasu dochÃ¡dzky podÄ¾a najbliÅ¾Å¡Ã­ch historickÃ½ch dÃ¡t.  
âœ” PrÃ­klad: Odhad nÃ¡vÅ¡tevnosti podujatia na zÃ¡klade podobnÃ½ch predchÃ¡dzajÃºcich akciÃ­.

| Typ regresie                    | Rovnica / princÃ­p                    | Typ modelu                          | PouÅ¾itie                           | PrÃ­klad                                                                                  |
|:--------------------------------|:-------------------------------------|:------------------------------------|:-----------------------------------|:-----------------------------------------------------------------------------------------|
| LineÃ¡rna regresia               | y = Î²â‚€ + Î²â‚Â·x + Îµ                    | ParametrickÃ½                        | JednoduchÃ© lineÃ¡rne vzÅ¥ahy         | Cena domu podÄ¾a vÃ½mery, mzda podÄ¾a odpracovanÃ½ch hodÃ­n, dopyt podÄ¾a ceny                 |
| ViacnÃ¡sobnÃ¡ lineÃ¡rna regresia   | y = Î²â‚€ + Î²â‚Â·xâ‚ + Î²â‚‚Â·xâ‚‚ + ... + Îµ     | ParametrickÃ½                        | Viacero vstupov                    | Cena auta podÄ¾a veku, znaÄky, vÃ½konu, najazdenÃ½ch km, spotreby                           |
| PolynomiÃ¡lna regresia           | y = Î²â‚€ + Î²â‚Â·x + Î²â‚‚Â·xÂ² + ... + Îµ      | ParametrickÃ½                        | NelineÃ¡rne vzÅ¥ahy                  | Rast rastliny v Äase, zmena teploty poÄas dÅˆa, pokles vÃ½konu batÃ©rie                     |
| Ridge regresia (L2)             | min ||y - XÎ²||Â² + Î»Â·||Î²||Â²           | ParametrickÃ½ (regularizovanÃ½)       | Multikolinearita                   | NÃ¡klady na marketing, vÃ½kon modelu podÄ¾a poÄtu iterÃ¡ciÃ­, vÃ½davky podÄ¾a kategÃ³riÃ­         |
| Lasso regresia (L1)             | min ||y - XÎ²||Â² + Î»Â·|Î²|              | ParametrickÃ½ (s vÃ½berom premennÃ½ch) | VÃ½ber relevantnÃ½ch vstupov         | Predikcia ceny nehnuteÄ¾nosti, vÃ½ber kÄ¾ÃºÄovÃ½ch premennÃ½ch, zjednoduÅ¡enie modelu           |
| Elastic Net                     | min ||y - XÎ²||Â² + Î»â‚Â·|Î²| + Î»â‚‚Â·||Î²||Â² | ParametrickÃ½ (kombinovanÃ½)          | KorelovanÃ© premennÃ©                | Predaj produktu z marketingovÃ½ch metrÃ­k, odhad vÃ½nosnosti reklamy, optimalizÃ¡cia kampanÃ­ |
| LogaritmickÃ¡ regresia           | ln(y) = Î²â‚€ + Î²â‚Â·x + Îµ                | ParametrickÃ½ (log-transformovanÃ½)   | Log-normÃ¡lne rozdelenie            | Predikcia populÃ¡cie, rast cien v Äase, poÄet pouÅ¾Ã­vateÄ¾ov aplikÃ¡cie                      |
| Rozhodovacie stromy             | PodmienkovÃ© delenie                  | NeparametrickÃ½                      | SegmentÃ¡cia a rozhodovanie         | VÃ½davky domÃ¡cnosti, odhad ceny podÄ¾a kategÃ³riÃ­, sprÃ¡vanie zÃ¡kaznÃ­kov                     |
| Support Vector Regression (SVR) | Îµ-insensitive loss + kernel          | ParametrickÃ½ / KernelovÃ½            | NelineÃ¡rne vzÅ¥ahy, vysokÃ¡ dimenzia | Predikcia cien akciÃ­, komplexnÃ© vzÅ¥ahy medzi trhmi, analÃ½za trendov                      |
| K-nearest neighbors (KNN)       | y_pred = priemer(y susedov)          | NeparametrickÃ½                      | PodobnosÅ¥ podÄ¾a vzdialenosti       | Cena Airbnb podÄ¾a okolia, odporÃºÄanie produktov, odhad nÃ¡kladov na zÃ¡klade podobnostÃ­    |


<a name="linearna-regresia"></a>
## ğŸ“ˆ 4. LineÃ¡rna regresia v scikit-learn

LineÃ¡rna regresia je zÃ¡kladnÃ½ model na predikciu spojitÃ½ch hodnÃ´t. Jej cieÄ¾om je nÃ¡jsÅ¥ optimÃ¡lnu priamku (alebo hyperrovinu), ktorÃ¡ minimalizuje chybu medzi predikovanÃ½mi a skutoÄnÃ½mi hodnotami.

### ğŸ“ Rovnica lineÃ¡rnej regresie  

**StrojovÃ© uÄenie / ML notÃ¡cia:** (pouÅ¾Ã­vanÃ¡ v machine learning, neurÃ³novÃ½ch sieÅ¥ach)  

$$
y = w_0 + w_1 x_1 + w_2 x_2 + \dots + w_n x_n  
$$

kde $$(w_i \)$$  sÃº koeficienty modelu a $$( x_i \)$$  vstupnÃ© premennÃ©.  

**MatematickÃ¡ a Å¡tatistickÃ¡ notÃ¡cia:** (pouÅ¾Ã­vanÃ¡ v Å¡tatistike, ekonometrii, vede)

$$ 
y = Î²0 + Î²1.x1 + Î²2.x2 + â‹¯ + Î²n.xn + Îµ  
$$

Kde:  
â€¢	$$y$$ â€“ zÃ¡vislÃ¡ premennÃ¡  
â€¢	$$x$$ â€“ nezÃ¡vislÃ¡ premennÃ¡  
â€¢	$$Î²â‚€$$ â€“ intercept (konÅ¡tanta)  
â€¢	$$Î²â‚$$ â€“ smernica (koeficient regresie)  
â€¢	$$Îµ$$ â€“ nÃ¡hodnÃ¡ chyba  


---

### ğŸ“¦ PrehÄ¾ad modelov v `sklearn.linear_model`

| Trieda / Model                        | Popis                                                                                 | Typ Ãºlohy       | PoznÃ¡mka / VlastnosÅ¥                     |
|--------------------------------------|----------------------------------------------------------------------------------------|------------------|-------------------------------------------|
| `LinearRegression`                   | ObyÄajnÃ¡ lineÃ¡rna regresia (metÃ³da najmenÅ¡Ã­ch Å¡tvorcov)                               | Regresia         | Bez regularizÃ¡cie                         |
| `Ridge`                              | LineÃ¡rna regresia s L2 regularizÃ¡ciou                                                  | Regresia         | TrestÃ¡ veÄ¾kÃ© koeficienty                 |
| `Lasso`                              | LineÃ¡rna regresia s L1 regularizÃ¡ciou                                                  | Regresia         | MÃ´Å¾e Ãºplne vynulovaÅ¥ niektorÃ© koeficienty |
| `ElasticNet`                         | KombinÃ¡cia L1 a L2 regularizÃ¡cie                                                       | Regresia         | FlexibilnÃ© nastavenie penalizÃ¡cie        |
| `RidgeCV`                            | Ridge s automatickÃ½m vÃ½berom parametra cez cross-validÃ¡ciu                            | Regresia         | InternÃ¡ validÃ¡cia                        |
| `LassoCV`                            | Lasso s vÃ½berom optimÃ¡lneho Î±                                                          | Regresia         | AutomatickÃ© ladenie                      |
| `ElasticNetCV`                       | ElasticNet s vÃ½berom parametrov cez cross-validÃ¡ciu                                    | Regresia         | AutomatickÃ½ tuning                       |
| `Lars`                               | Least Angle Regression â€“ efektÃ­vna pre veÄ¾a premennÃ½ch                                 | Regresia         | AlternatÃ­va k Lasso                      |
| `LarsCV`                             | Lars s vÃ½berom cez cross-validÃ¡ciu                                                     | Regresia         |                                          |
| `LassoLars`                          | Lasso implementovanÃ© pomocou LARS algoritmu                                            | Regresia         | RÃ½chle pri veÄ¾kom poÄte vstupov          |
| `LassoLarsCV`                        | Verzia s vÃ½berom parametra cez cross-validÃ¡ciu                                        | Regresia         |                                          |
| `LassoLarsIC`                        | VÃ½ber modelu cez AIC / BIC                                                            | Regresia         | InformaÄnÃ© kritÃ©riÃ¡                      |
| `OrthogonalMatchingPursuit`         | Greedy algoritmus pre riedku regresiu                                                  | Regresia         | Pre riedke (sparse) modely               |
| `OrthogonalMatchingPursuitCV`       | Verzia s vÃ½berom poÄtu koeficientov                                                    | Regresia         |                                          |
| `HuberRegressor`                    | RobustnÃ¡ regresia odolnÃ¡ voÄi odÄ¾ahlÃ½m hodnotÃ¡m                                        | Regresia         | Kombinuje vlastnosti Ridge a L1          |
| `RANSACRegressor`                   | Detekcia odÄ¾ahlÃ½ch hodnÃ´t cez iteratÃ­vny vÃ½ber vzoriek                                | Regresia         | OdolnÃ½ voÄi Å¡umu                         |
| `TheilSenRegressor`                 | RobustnÃ¡ Å¡tatistickÃ¡ regresia                                                         | Regresia         | PomalejÅ¡Ã­, ale stabilnÃ½ pri outlieroch   |
| `BayesianRidge`                     | BayesovskÃ¡ lineÃ¡rna regresia                                                          | Regresia         | PravdepodobnostnÃ½ prÃ­stup                |
| `ARDRegression`                     | AutomatickÃ© urÄenie relevantnÃ½ch premennÃ½ch                                           | Regresia         | AutomatickÃ© vynulovanie nerelevantnÃ½ch   |
| `PoissonRegressor`                 | Poissonova regresia pre poÄetnÃ© dÃ¡ta                                                  | Regresia         | GeneralizovanÃ½ lineÃ¡rny model (GLM)      |
| `GammaRegressor`                    | Regressia s gama rozdelenÃ­m                                                           | Regresia         | GLM pre kladnÃ© spojitÃ© hodnoty           |
| `TweedieRegressor`                  | GeneralizovanÃ½ lineÃ¡rny model pre rÃ´zne distribÃºcie                                   | Regresia         | FlexibilnÃ© nastavenie parametra          |
| `QuantileRegressor`                 | KvantilovÃ¡ regresia â€“ predikcia percentilu (nie priemeru)                             | Regresia         | VhodnÃ© pre odhad intervalov              |
| `LogisticRegression`                | BinÃ¡rna alebo viactriedna klasifikÃ¡cia                                                 | KlasifikÃ¡cia     | NajÄastejÅ¡ie pouÅ¾Ã­vanÃ½ lineÃ¡rny klasifikÃ¡tor |
| `LogisticRegressionCV`             | LogisticRegression s vÃ½berom parametra cez cross-validÃ¡ciu                            | KlasifikÃ¡cia     | AutomatickÃ© ladenie                      |
| `Perceptron`                        | JednoduchÃ½ neurÃ³n pre binÃ¡rnu klasifikÃ¡ciu                                            | KlasifikÃ¡cia     | Bez skrytej vrstvy                       |
| `PassiveAggressiveClassifier`       | EfektÃ­vny algoritmus pre veÄ¾kÃ© datasety (online uÄenie)                               | KlasifikÃ¡cia     | VhodnÃ© pre streamovanie dÃ¡t              |
| `PassiveAggressiveRegressor`        | Variant pre regresiu                                                                 | Regresia         | Online uÄenie                            |
| `SGDClassifier`                     | KlasifikÃ¡cia pomocou stochastickÃ©ho gradientu                                         | KlasifikÃ¡cia     | VeÄ¾mi rÃ½chly, online uÄenie              |
| `SGDRegressor`                      | Regresia pomocou SGD                                                                  | Regresia         | VeÄ¾kÃ© datasety, regularizÃ¡cia            |
| `SGDOneClassSVM`                    | Jednotriedna detekcia anomÃ¡liÃ­ pomocou SGD                                            | AnomÃ¡lie         | ExperimentÃ¡lne                           |

---

### ğŸ§ª PrÃ­klad 1: JednoduchÃ¡ lineÃ¡rna regresia (1 vstup)

```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error

# Vytvorenie modelu a natrÃ©novanie na jednom atribÃºte (napr. BMI)
model = LinearRegression()
model.fit(X_train[['bmi']], y_train)

# Predikcia hodnÃ´t na testovacej mnoÅ¾ine
preds = model.predict(X_test[['bmi']])

# Vyhodnotenie modelu
print("R2 score:", r2_score(y_test, preds))
print("MSE:", mean_squared_error(y_test, preds))
```

---

### ğŸ§ª PrÃ­klad 2: VizualizÃ¡cia regresnej priamky

```python
import matplotlib.pyplot as plt

# SkutoÄnÃ© vs. predikovanÃ© hodnoty
plt.scatter(X_test['bmi'], y_test, color='gray', label='SkutoÄnÃ©')
plt.plot(X_test['bmi'], preds, color='red', label='PredikovanÃ©')
plt.xlabel('BMI')
plt.ylabel('CieÄ¾ovÃ¡ premennÃ¡')
plt.title('LineÃ¡rna regresia: BMI vs. cieÄ¾')
plt.legend()
plt.show()
```

---

### ğŸ§ª PrÃ­klad 3: Zobrazenie koeficientov modelu

```python
# Koeficient (sklon priamky)
print("Koeficient w1:", model.coef_[0])

# AbsolÃºtna hodnota intercept (posun priamky)
print("Intercept w0:", model.intercept_)
```

---

### ğŸ§ª PrÃ­klad 4: Viac atribÃºtov naraz â€“ multivariaÄnÃ¡ lineÃ¡rna regresia

```python
# VÅ¡etky atribÃºty pouÅ¾itÃ© na trÃ©ning
model_multi = LinearRegression()
model_multi.fit(X_train, y_train)

# Predikcia a vyhodnotenie
preds_multi = model_multi.predict(X_test)
print("R2 (viac atribÃºtov):", r2_score(y_test, preds_multi))
```


```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
import matplotlib.pyplot as plt

# TrÃ©ning modelu na jednom atribÃºte (napr. BMI)
model = LinearRegression()
model.fit(X_train[['bmi']], y_train)

# Predikcia hodnÃ´t
preds = model.predict(X_test[['bmi']])

# Vyhodnotenie vÃ½konu modelu
print("R2 score:", r2_score(y_test, preds))
print("Mean Squared Error:", mean_squared_error(y_test, preds))

# VizualizÃ¡cia
plt.scatter(X_test['bmi'], y_test, color='blue', label='SkutoÄnÃ© hodnoty')
plt.plot(X_test['bmi'], preds, color='red', label='PredikovanÃ© hodnoty')
plt.xlabel('BMI')
plt.ylabel('CieÄ¾ovÃ¡ hodnota')
plt.title('LineÃ¡rna regresia na BMI')
plt.legend()
plt.show()
```

---

<a name="viacnasobna-regresia"></a>
## ğŸ§® 5. ViacnÃ¡sobnÃ¡ regresia a vÃ½ber parametrov

ViacnÃ¡sobnÃ¡ lineÃ¡rna regresia rozÅ¡iruje jednoduchÃº regresiu na viac vstupnÃ½ch premennÃ½ch. UmoÅ¾Åˆuje lepÅ¡ie modelovaÅ¥ komplexnejÅ¡ie vzÅ¥ahy v dÃ¡tach.

### ğŸ“ Rovnica viacnÃ¡sobnej lineÃ¡rnej regresie

**StrojovÃ© uÄenie / ML notÃ¡cia:** (pouÅ¾Ã­vanÃ¡ v machine learning, neurÃ³novÃ½ch sieÅ¥ach)    

$$  
y = wâ‚€ + wâ‚Â·xâ‚ + wâ‚‚Â·xâ‚‚ + â€¦ + wâ‚™Â·xâ‚™  
$$  

kde $$xâ‚...xâ‚™$$ sÃº vstupnÃ© atribÃºty a $$wâ‚...wâ‚™$$ ich koeficienty (vÃ¡hy/weights), Äasto sa nepÃ­Å¡e Îµ (predikcia bez explicitnej chyby).

**MatematickÃ¡ a Å¡tatistickÃ¡ notÃ¡cia:** (pouÅ¾Ã­vanÃ¡ v Å¡tatistike, ekonometrii, vede)  

$$  
y = Î²â‚€ + Î²â‚ xâ‚ + Î²2 xâ‚‚ + â‹¯ + Î²â‚™ xâ‚™ + Îµ  
$$  

kde $$xâ‚...xâ‚™$$ sÃº vstupnÃ© atribÃºty a $$wâ‚...wâ‚™$$ ich koeficienty (vÃ¡hy/weights).

â€¢  $$y$$ â€“ zÃ¡vislÃ¡ premennÃ¡ (predikovanÃ¡ hodnota)  
â€¢  $$xâ‚, xâ‚‚, ..., xâ‚™$$ â€“ nezÃ¡vislÃ© premennÃ© (vysvetÄ¾ujÃºce premennÃ©)  
â€¢  $$Î²â‚€$$ â€“ intercept (konÅ¡tanta)  
â€¢  $$Î²â‚, Î²â‚‚, ..., Î²â‚™$$ â€“ regresnÃ© koeficienty (vÃ¡hy premennÃ½ch)  
â€¢  $$Îµ$$ â€“ nÃ¡hodnÃ¡ chyba (reziduÃ¡l)  

PrÃ­klad pre 3 premennÃ©:  

$$
y = Î²0 + Î²1.x1 + Î²2.x2 + Î²3.x3 + Îµ
$$

PouÅ¾Ã­va sa naprÃ­klad na predikciu cien, vÃ½nosov alebo skÃ³re na zÃ¡klade viacerÃ½ch vstupnÃ½ch faktorov.

---

### ğŸ§ª PrÃ­klad 1: TrÃ©ning viacnÃ¡sobnÃ©ho modelu so vÅ¡etkÃ½mi atribÃºtmi

```python
from sklearn.linear_model import LinearRegression

model_multi = LinearRegression()
model_multi.fit(X_train, y_train)

# Predikcia
y_pred = model_multi.predict(X_test)

# Vyhodnotenie
from sklearn.metrics import r2_score, mean_squared_error
print("R2:", r2_score(y_test, y_pred))
print("MSE:", mean_squared_error(y_test, y_pred))
```

---

### ğŸ§ª PrÃ­klad 2: NormalizÃ¡cia vstupov pomocou StandardScaler

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

model_scaled = LinearRegression()
model_scaled.fit(X_train_scaled, y_train)

# Predikcia a vyhodnotenie
y_pred_scaled = model_scaled.predict(X_test_scaled)
print("R2 (Å¡kÃ¡lovanÃ©):", r2_score(y_test, y_pred_scaled))
```

---

### ğŸ§ª PrÃ­klad 3: VÃ½ber najlepÅ¡Ã­ch atribÃºtov pomocou SelectKBest

```python
from sklearn.feature_selection import SelectKBest, f_regression

# Vyber 5 najrelevantnejÅ¡Ã­ch atribÃºtov
selector = SelectKBest(score_func=f_regression, k=5)
X_train_selected = selector.fit_transform(X_train_scaled, y_train)
X_test_selected = selector.transform(X_test_scaled)

model_kbest = LinearRegression()
model_kbest.fit(X_train_selected, y_train)
print("R2 (SelectKBest):", model_kbest.score(X_test_selected, y_test))
```

â¡ï¸ VÃ½ber atribÃºtov pomÃ¡ha znÃ­Å¾iÅ¥ zloÅ¾itosÅ¥ modelu, odstrÃ¡niÅ¥ Å¡um a zvÃ½Å¡iÅ¥ interpretovateÄ¾nosÅ¥.
â¡ï¸ NormalizÃ¡cia zaisÅ¥uje rovnakÃ© vÃ¡hovÃ© podmienky pre vÅ¡etky atribÃºty.
â¡ï¸ OdporÃºÄam testovaÅ¥ rÃ´zne kombinÃ¡cie atribÃºtov a porovnÃ¡vaÅ¥ metriky.


```python
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.feature_selection import SelectKBest, f_regression

# NormalizÃ¡cia vstupnÃ½ch Ãºdajov
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_train)

# VÃ½ber 5 najlepÅ¡Ã­ch atribÃºtov podÄ¾a korelÃ¡cie s cieÄ¾ovou premennou
selector = SelectKBest(score_func=f_regression, k=5)
X_selected = selector.fit_transform(X_scaled, y_train)

# TrÃ©ning viacnÃ¡sobnÃ©ho regresnÃ©ho modelu
model = LinearRegression()
model.fit(X_selected, y_train)

# Vyhodnotenie na testovacÃ­ch dÃ¡tach
X_test_scaled = scaler.transform(X_test)
X_test_selected = selector.transform(X_test_scaled)

preds = model.predict(X_test_selected)
print("R2 score:", r2_score(y_test, preds))
print("Mean Squared Error:", mean_squared_error(y_test, preds))
```

---

<a name="zdroje-a-literatura"></a>
## ğŸ“š Zdroje a literatÃºra k strojovÃ©mu uÄeniu a scikit-learn

### ğŸ“˜ Top knihy â€“ Anglicky

| NÃ¡zov | Autor | Popis |
|-------|-------|-------|
| Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow | AurÃ©lien GÃ©ron | NajkomplexnejÅ¡ia kniha pre ML v Pythone. Obsahuje teÃ³riu aj praktickÃ© prÃ­klady. |
| Python Machine Learning | Sebastian Raschka, Vahid Mirjalili | Kniha zameranÃ¡ na praktickÃº implementÃ¡ciu ML algoritmov v Pythone. |
| Introduction to Machine Learning with Python | Andreas MÃ¼ller, Sarah Guido | VÃ½bornÃ½ Ãºvod do ML so zameranÃ­m na scikit-learn. |
| Machine Learning Yearning | Andrew Ng | StrategickÃ½ pohÄ¾ad na budovanie ML systÃ©mov (voÄ¾ne dostupnÃ© PDF). |
| Pattern Recognition and Machine Learning | Christopher Bishop | HlbÅ¡ie teoretickÃ© zÃ¡klady ML. |
| Data Science from Scratch | Joel Grus | ZÃ¡klady ML s implementÃ¡ciou algoritmov "od nuly". |

### ğŸ“™ Knihy a zdroje â€“ ÄŒesky a Slovensky

| NÃ¡zov | Autor | Popis |
|-------|-------|-------|
| UÄÃ­me se strojovÃ© uÄenÃ­ | OndÅ™ej VaÅˆo | ÄŒeskÃ¡ prÃ­ruÄka s praktickÃ½mi Ãºlohami v Pythone. |
| ZÃ¡klady strojovÃ©ho uÄenia | kol. autorov | Ãšvod do ML a zÃ¡kladnÃ© modely v ÄeÅ¡tine. |
| Python pro analÃ½zu dat | Wes McKinney (CZ preklad) | ZameranÃ© na prÃ¡cu s dÃ¡tami v Pandas, vhodnÃ© ako zÃ¡klad pre ML. |
| StrojovÃ© uÄenie v Pythone | Miroslav Reiter | PraktickÃ½ kurz pre zaÄiatoÄnÃ­kov s dÃ´razom na regresiu a scikit-learn. |

> ğŸ§  PoznÃ¡mka: ÄŒeskoslovenskÃ© tituly sÃº Äasto pre zaÄiatoÄnÃ­kov a pomÃ¡hajÃº pochopiÅ¥ zÃ¡klady v rodnom jazyku.

### ğŸŒ OficiÃ¡lna dokumentÃ¡cia a online zdroje

| NÃ¡zov | Popis | Odkaz |
|-------|--------|--------|
| scikit-learn User Guide | OficiÃ¡lna dokumentÃ¡cia a prÃ­ruÄky | [scikit-learn.org](https://scikit-learn.org/stable/user_guide.html) |
| scikit-learn API Reference | DetailnÃ© API popisy tried a funkciÃ­ | [scikit-learn.org API](https://scikit-learn.org/stable/modules/classes.html) |
| sklearn-examples GitHub | PrÃ­klady projektov s pouÅ¾itÃ­m scikit-learn | [github.com/scikit-learn](https://github.com/scikit-learn/scikit-learn) |
| Kaggle Learn ML | Online micro-kurzy a sÃºÅ¥aÅ¾e | [kaggle.com/learn](https://www.kaggle.com/learn/intro-to-machine-learning) |
| Machine Learning Mastery | Blog a nÃ¡vody pre praktickÃ© ML | [machinelearningmastery.com](https://machinelearningmastery.com) |
| Google AI Hub | NÃ¡stroje, datasetovÃ© repozitÃ¡re a prÃ­klady | [ai.google](https://ai.google/tools/) |
| Towards Data Science | Blogy a tutoriÃ¡ly od expertov z ML komunity | [towardsdatascience.com](https://towardsdatascience.com) |

---
<a name="odporucania"></a>
## âœ… OdporÃºÄania ML, regresia a Scikit-Learn

- ğŸ“¦ PouÅ¾i `pip install scikit-learn pandas matplotlib` na inÅ¡talÃ¡ciu
- ğŸ§ª Pracuj v prostredÃ­ Jupyter Notebook (napr. Jetbrains Datalore, VS Code, Google Colab)
- ğŸ’¾ PouÅ¾Ã­vaj `.fit()` na uÄenie modelu a `.predict()` na predikciu novÃ½ch vstupov
- ğŸ” VyuÅ¾Ã­vaj `train_test_split()` na oddelenie trÃ©ningovÃ½ch a testovacÃ­ch dÃ¡t
- ğŸ›  SkÃºÅ¡aj rÃ´zne metriky vÃ½konu (napr. RÂ², MSE, MAE) podÄ¾a typu Ãºlohy
- ğŸ“Š Vizualizuj vÃ½sledky cez `matplotlib` alebo `seaborn` pre lepÅ¡ie porozumenie dÃ¡t
- ğŸ§  Pri vÃ½bere atribÃºtov pouÅ¾i `SelectKBest`, `RFE` alebo `feature_importances_`
- ğŸ” PouÅ¾Ã­vaj `cross_val_score()` na krÃ­Å¾ovÃº validÃ¡ciu modelu
- ğŸ§ª Nezabudni na `StandardScaler()` alebo `MinMaxScaler()` pri Å¡kÃ¡lovanÃ­ Ãºdajov
- ğŸ—ƒï¸ Na prÃ¡cu s vÃ¤ÄÅ¡Ã­mi datasetmi vyskÃºÅ¡aj `fetch_california_housing` alebo vlastnÃ© CSV sÃºbory
- ğŸ§¾ Sleduj novinky na [scikit-learn release log](https://scikit-learn.org/stable/whats_new.html) pre novÃ© funkcie a zmeny

---

