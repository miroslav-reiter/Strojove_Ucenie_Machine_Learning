# ğŸ¤– Online kurz: StrojovÃ© uÄenie (Machine Learning) v Pythone so scikit-learn

> PraktickÃ½ kurz pre zaÄiatoÄnÃ­kov â€“ Regresia v ML, scikit-learn, modelovanie, trÃ©ning a vyhodnocovanie

---

## ğŸ“˜ Obsah kurzu

01. [**ğŸ” Ãšvod do strojovÃ©ho uÄenia a regresie**](#uvod-ml-regresia))  
02. [**ğŸ§  PrehÄ¾ad typov regresii**](#prehlad-typov-regresii)
03. [**ğŸ“¦ HlavnÃ© datasety v sklearn.datasets**](#prehlad-datasety)  
04. [**ğŸ“ˆ LineÃ¡rna regresia v scikit-learn**](#linearna-regresia)  
05. [**ğŸ§® ViacnÃ¡sobnÃ¡ regresia a vÃ½ber parametrov**](#viacnasobna-regresia)  
06. [**ğŸ“š Zdroje a literatÃºra k strojovemu uceniu a scikit-learn**](#zdroje-a-literatura)  
07. [**âœ… OdporÃºÄania ML, regresia a Scikit-Learn**](#odporucania)

---

<a name="uvod-ml-regresia"></a>
## ğŸ” 1. Ãšvod do strojovÃ©ho uÄenia a regresie

V tejto Ãºvodnej Äasti sa zoznÃ¡mime so zÃ¡kladnÃ½mi pojmami, rozdielmi medzi typmi ML Ãºloh, kniÅ¾nicou scikit-learn a jednoduchÃ½mi praktickÃ½mi prÃ­kladmi.

### ğŸ¯ ZÃ¡kladnÃ© pojmy

- **Supervised learning (uÄenie s uÄiteÄ¾om)** â€“ algoritmus sa uÄÃ­ na zÃ¡klade oznaÄenÃ½ch dÃ¡t (X vstupy, y vÃ½stupy)
- **Training (trÃ©ning)** â€“ fÃ¡za uÄenia modelu na zÃ¡klade historickÃ½ch Ãºdajov
- **Testing (testovanie)** â€“ overenie vÃ½konu modelu na novÃ½ch Ãºdajoch, ktorÃ© nevidel
- **Regresia vs. klasifikÃ¡cia**:
  - *Regresia* predpovedÃ¡ **spojitÃ© hodnoty** (napr. cena, teplota)
  - *KlasifikÃ¡cia* predpovedÃ¡ **kategÃ³rie** (napr. Ã¡no/nie, trieda A/B/C)

### ğŸ§© Typy regresiÃ­ (prehÄ¾ad)

- **JednoduchÃ¡ lineÃ¡rna regresia** â€“ 1 vstupnÃ¡ premennÃ¡ (napr. vÃ½Å¡ka â†’ hmotnosÅ¥)
- **ViacnÃ¡sobnÃ¡ lineÃ¡rna regresia** â€“ viac vstupov (napr. vÃ½Å¡ka, vek, BMI â†’ hmotnosÅ¥)
- **PolynomiÃ¡lna regresia** â€“ rozÅ¡Ã­renie lineÃ¡rnej pomocou nelineÃ¡rnych zloÅ¾iek

---

### ğŸ§ª PrÃ­klad 1: NaÄÃ­tanie dÃ¡t a zÃ¡kladnÃ¡ Å¡tatistika

```python
from sklearn.datasets import load_diabetes
import pandas as pd

# NaÄÃ­tanie datasetu (zabudovanÃ½ dataset s Ãºdajmi o cukrovke)
data = load_diabetes(as_frame=True)
df = data.frame

# Zobrazenie prvÃ½ch 5 riadkov
print(df.head())

# ZÃ¡kladnÃ¡ Å¡tatistika
print(df.describe())
```

---

### ğŸ§ª PrÃ­klad 2: Rozdelenie dÃ¡t na trÃ©ningovÃº a testovaciu mnoÅ¾inu

```python
from sklearn.model_selection import train_test_split

X = df.drop(columns='target')  # vstupy (atribÃºty)
y = df['target']               # cieÄ¾ovÃ¡ premennÃ¡

# Rozdelenie na 80 % trÃ©ning a 20 % test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("TrÃ©ningovÃ¡ mnoÅ¾ina:", X_train.shape)
print("Testovacia mnoÅ¾ina:", X_test.shape)
```

---

### ğŸ§ª PrÃ­klad 3: ZÃ¡kladnÃ¡ vizualizÃ¡cia vzÅ¥ahu medzi atribÃºtom a cieÄ¾om

```python
import matplotlib.pyplot as plt

# Porovnanie BMI a cieÄ¾ovej hodnoty
plt.scatter(X['bmi'], y, color='green', alpha=0.5)
plt.xlabel('BMI')
plt.ylabel('CieÄ¾ovÃ¡ premennÃ¡ (target)')
plt.title('VzÅ¥ah medzi BMI a cieÄ¾om')
plt.grid(True)
plt.show()
```

---

### ğŸ§ª PrÃ­klad 4: PrehÄ¾ad funkciÃ­ kniÅ¾nice scikit-learn

```python
import sklearn

# Verzia kniÅ¾nice
print("scikit-learn verzia:", sklearn.__version__)

# Skontroluj dostupnÃ© moduly: linear_model, model_selection, metrics...
from sklearn import linear_model, metrics, preprocessing
print(dir(linear_model))  # dostupnÃ© modely v linear_model
```

TÃ½mto sme zÃ­skali zÃ¡kladnÃ½ prehÄ¾ad o tom:
- ako vyzerajÃº dÃ¡ta,
- ako sa rozdeÄ¾ujÃº na trÃ©ning a test,
- ako vizualizovaÅ¥ vzÅ¥ahy a
- Äo ponÃºka kniÅ¾nica scikit-learn.

```python
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
import pandas as pd

# NaÄÃ­tanie vstupnÃ©ho datasetu diabetes
X, y = load_diabetes(return_X_y=True, as_frame=True)

# Rozdelenie na trÃ©ningovÃº a testovaciu mnoÅ¾inu (80:20)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# VÃ½pis tvaru datasetu
print(X_train.shape, X_test.shape)
```

---
<a name="prehlad-datasety"></a>
## ğŸ“¦ 2. HlavnÃ© datasety v `sklearn.datasets`

> PrehÄ¾ad zabudovanÃ½ch datasetov v kniÅ¾nici `scikit-learn`, rozdelenÃ½ podÄ¾a typu Ãºloh.

### ğŸ“¦ KlasifikaÄnÃ© datasety (pre Ãºlohy rozpoznÃ¡vania kategÃ³riÃ­)

| Dataset | Popis |
|--------|-------|
| `load_iris()` | ğŸª» Iris â€“ klasifikÃ¡cia druhov kvetov na zÃ¡klade rozmerov okvetia. |
| `load_digits()` | ğŸ”¢ Rukou pÃ­sanÃ© ÄÃ­slice (0â€“9) â€“ obrÃ¡zky 8x8 pixelov. |
| `load_wine()` | ğŸ· ChemickÃ© vlastnosti vÃ­n â€“ rozpoznanie odrody. |
| `load_breast_cancer()` | ğŸ§ª DÃ¡ta o nÃ¡doroch prsnÃ­ka â€“ klasifikÃ¡cia malÃ­gnych a benÃ­gnych. |
| `fetch_20newsgroups()` | ğŸ“° TextovÃ© dÃ¡ta z 20 kategÃ³riÃ­ diskusnÃ½ch skupÃ­n. |
| `fetch_20newsgroups_vectorized()` | ğŸ”¤ PredspracovanÃ¡ verzia predchÃ¡dzajÃºceho. |
| `fetch_covtype()` | ğŸŒ² LesnÃ© krytie â€“ predikcia typu vegetÃ¡cie na zÃ¡klade geografickÃ½ch znakov. |
| `fetch_kddcup99()` | ğŸŒ SieÅ¥ovÃ½ traffic â€“ detekcia anomÃ¡liÃ­ a Ãºtokov. |
| `fetch_lfw_people()` | ğŸ‘¤ RozpoznÃ¡vanie osÃ´b na obrÃ¡zkoch (LFW). |
| `fetch_lfw_pairs()` | ğŸ‘¥ PorovnÃ¡vanie tvÃ¡rÃ­ â€“ sÃº na dvoch obrÃ¡zkoch rovnakÃ© osoby? |
| `fetch_olivetti_faces()` | ğŸ§‘â€ğŸ¦± Dataset tvÃ¡rÃ­ â€“ rozpoznÃ¡vanie identÃ­t. |
| `fetch_rcv1()` | ğŸ“° Reuters texty â€“ multilabel klasifikÃ¡cia tÃ©m. |

### ğŸ“ˆ RegresnÃ© datasety

| Dataset | Popis |
|--------|-------|
| `load_diabetes()` | ğŸ§¬ Diabetes â€“ predikcia progresie choroby. |
| `fetch_california_housing()` | ğŸ˜ï¸ Predikcia cien nehnuteÄ¾nostÃ­ v Kalifornii. |

### ğŸ’ª InÃ© a Å¡peciÃ¡lne datasety

| Dataset | Popis |
|--------|-------|
| `load_linnerud()` | ğŸƒâ€â™‚ï¸ FyzickÃ© vÃ½kony a fyziologickÃ© dÃ¡ta. |
| `fetch_species_distributions()` | ğŸ¦ VÃ½skyt druhov podÄ¾a geografie. |
| `load_files()` | ğŸ“‚ NaÄÃ­tanie vlastnÃ½ch textovÃ½ch datasetov. |

### ğŸ–¼ï¸ Datasety s obrÃ¡zkami

| Dataset | Popis |
|--------|-------|
| `load_sample_image()` | ğŸ–¼ï¸ JednotlivÃ½ ukÃ¡Å¾kovÃ½ obrÃ¡zok (napr. ÄÃ­nska zÃ¡hrada). |
| `load_sample_images()` | ğŸ§© SÃºbor ukÃ¡Å¾kovÃ½ch obrÃ¡zkov. |

### âš™ï¸ Utility a nÃ¡stroje

| Funkcia | Popis |
|--------|-------|
| `clear_data_home()` | ğŸ§¹ VymaÅ¾e cache dÃ¡t scikit-learn. |
| `get_data_home()` | ğŸ“ ZÃ­ska cestu k dÃ¡tovej zloÅ¾ke. |
| `fetch_openml()` | ğŸŒ NaÄÃ­tanie datasetov z OpenML. |
| `fetch_file()` | ğŸ“¥ Stiahne sÃºbor z webu do cache. |
| `load_svmlight_file()` | ğŸ“„ NaÄÃ­tanie SVMlight/libSVM formÃ¡tu. |
| `load_svmlight_files()` | ğŸ“„ Viacero SVMlight sÃºborov. |
| `dump_svmlight_file()` | ğŸ’¾ Export dÃ¡t do SVMlight. |

> Viac info: [sklearn.datasets API](https://scikit-learn.org/stable/api/sklearn.datasets.html#module-sklearn.datasets)

<a name="prehlad-typov-regresii"></a>
## ğŸ§  3. PrehÄ¾ad typov regresiÃ­

RegresnÃ© modely sÃº urÄenÃ© na predpovedanie spojitÃ½ch hodnÃ´t. V tejto kapitole si predstavÃ­me zÃ¡kladnÃ© typy regresiÃ­, ich vÃ½hody, nevÃ½hody a ukÃ¡Å¾eme si jednoduchÃ© prÃ­klady.

### ğŸ“Š Typy regresie:

| Typ regresie               | Popis | PrÃ­klad pouÅ¾itia |
|----------------------------|-------|------------------|
| JednoduchÃ¡ lineÃ¡rna       | 1 vstupnÃ¡ premennÃ¡, lineÃ¡rny vzÅ¥ah | vÃ½Å¡ka â†’ hmotnosÅ¥ |
| ViacnÃ¡sobnÃ¡ lineÃ¡rna      | Viac vstupnÃ½ch premennÃ½ch | vek, BMI, prÃ­jem â†’ krvnÃ½ tlak |
| PolynomiÃ¡lna regresia     | Obsahuje nelineÃ¡rne Äleny (xÂ², xÂ³, ...) | vekÂ² â†’ vÃ½davky |
| Ridge regresia            | LineÃ¡rna regresia s L2 regularizÃ¡ciou | vysokodimenzionÃ¡lne dÃ¡ta |
| Lasso regresia            | LineÃ¡rna s L1 regularizÃ¡ciou (vÃ½ber premennÃ½ch) | selekcia atribÃºtov |
| ElasticNet                | KombinÃ¡cia L1 a L2 | kompromis medzi Ridge a Lasso |
| LogaritmickÃ¡ regresia     | ZaloÅ¾enÃ¡ na logaritmickej transformÃ¡cii | vÃ½skyt udalostÃ­ |
| RobustnÃ¡ regresia         | OdolnÃ¡ voÄi extrÃ©mnym hodnotÃ¡m (outlierom) | analÃ½za miezd |

---

### ğŸ§ª PrÃ­klad: PolynomiÃ¡lna regresia

```python
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline
from sklearn.linear_model import LinearRegression

# PouÅ¾Ã­vame len jeden atribÃºt pre prehÄ¾adnosÅ¥
X_poly = X_train[['bmi']]
y_poly = y_train

# Vytvorenie modelu s polynÃ³mom 2. stupÅˆa
poly_model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())
poly_model.fit(X_poly, y_poly)

# Predikcia
X_test_poly = X_test[['bmi']]
y_pred_poly = poly_model.predict(X_test_poly)
```

---

### ğŸ§ª PrÃ­klad: Ridge a Lasso regresia

```python
from sklearn.linear_model import Ridge, Lasso

# Ridge (L2 regularizÃ¡cia)
ridge_model = Ridge(alpha=1.0)
ridge_model.fit(X_train, y_train)
print("Ridge R2:", ridge_model.score(X_test, y_test))

# Lasso (L1 regularizÃ¡cia)
lasso_model = Lasso(alpha=0.1)
lasso_model.fit(X_train, y_train)
print("Lasso R2:", lasso_model.score(X_test, y_test))
```

â¡ï¸ KaÅ¾dÃ½ regresnÃ½ model sa hodÃ­ na inÃ½ typ Ãºlohy a dÃ¡ta. DÃ´leÅ¾itÃ© je analyzovaÅ¥:
- linearitu vzÅ¥ahu medzi premennÃ½mi,
- poÄet a korelÃ¡ciu vstupov,
- prÃ­tomnosÅ¥ extrÃ©mnych hodnÃ´t,
- a poÅ¾iadavky na interpretÃ¡ciu vs. vÃ½kon.

â¡ï¸ V ÄalÅ¡ej Äasti sa pozrieme na **lineÃ¡rnu regresiu** v praxi â€“ jej vÃ½poÄet, vizualizÃ¡ciu a interpretÃ¡ciu.



<a name="linearna-regresia"></a>
## ğŸ“ˆ 4. LineÃ¡rna regresia v scikit-learn

LineÃ¡rna regresia je zÃ¡kladnÃ½ model na predikciu spojitÃ½ch hodnÃ´t. Jej cieÄ¾om je nÃ¡jsÅ¥ optimÃ¡lnu priamku (alebo hyperrovinu), ktorÃ¡ minimalizuje chybu medzi predikovanÃ½mi a skutoÄnÃ½mi hodnotami.

### ğŸ“ Rovnica lineÃ¡rnej regresie

$$
y = w_0 + w_1 x_1 + w_2 x_2 + \dots + w_n x_n
$$


kde $$(w_i \)$$  sÃº koeficienty modelu a $$( x_i \)$$  vstupnÃ© premennÃ©.

---

### ğŸ§ª PrÃ­klad 1: JednoduchÃ¡ lineÃ¡rna regresia (1 vstup)

```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error

# Vytvorenie modelu a natrÃ©novanie na jednom atribÃºte (napr. BMI)
model = LinearRegression()
model.fit(X_train[['bmi']], y_train)

# Predikcia hodnÃ´t na testovacej mnoÅ¾ine
preds = model.predict(X_test[['bmi']])

# Vyhodnotenie modelu
print("R2 score:", r2_score(y_test, preds))
print("MSE:", mean_squared_error(y_test, preds))
```

---

### ğŸ§ª PrÃ­klad 2: VizualizÃ¡cia regresnej priamky

```python
import matplotlib.pyplot as plt

# SkutoÄnÃ© vs. predikovanÃ© hodnoty
plt.scatter(X_test['bmi'], y_test, color='gray', label='SkutoÄnÃ©')
plt.plot(X_test['bmi'], preds, color='red', label='PredikovanÃ©')
plt.xlabel('BMI')
plt.ylabel('CieÄ¾ovÃ¡ premennÃ¡')
plt.title('LineÃ¡rna regresia: BMI vs. cieÄ¾')
plt.legend()
plt.show()
```

---

### ğŸ§ª PrÃ­klad 3: Zobrazenie koeficientov modelu

```python
# Koeficient (sklon priamky)
print("Koeficient w1:", model.coef_[0])

# AbsolÃºtna hodnota intercept (posun priamky)
print("Intercept w0:", model.intercept_)
```

---

### ğŸ§ª PrÃ­klad 4: Viac atribÃºtov naraz â€“ multivariaÄnÃ¡ lineÃ¡rna regresia

```python
# VÅ¡etky atribÃºty pouÅ¾itÃ© na trÃ©ning
model_multi = LinearRegression()
model_multi.fit(X_train, y_train)

# Predikcia a vyhodnotenie
preds_multi = model_multi.predict(X_test)
print("R2 (viac atribÃºtov):", r2_score(y_test, preds_multi))
```


```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
import matplotlib.pyplot as plt

# TrÃ©ning modelu na jednom atribÃºte (napr. BMI)
model = LinearRegression()
model.fit(X_train[['bmi']], y_train)

# Predikcia hodnÃ´t
preds = model.predict(X_test[['bmi']])

# Vyhodnotenie vÃ½konu modelu
print("R2 score:", r2_score(y_test, preds))
print("Mean Squared Error:", mean_squared_error(y_test, preds))

# VizualizÃ¡cia
plt.scatter(X_test['bmi'], y_test, color='blue', label='SkutoÄnÃ© hodnoty')
plt.plot(X_test['bmi'], preds, color='red', label='PredikovanÃ© hodnoty')
plt.xlabel('BMI')
plt.ylabel('CieÄ¾ovÃ¡ hodnota')
plt.title('LineÃ¡rna regresia na BMI')
plt.legend()
plt.show()
```

---

<a name="viacnasobna-regresia"></a>
## ğŸ§® 5. ViacnÃ¡sobnÃ¡ regresia a vÃ½ber parametrov

ViacnÃ¡sobnÃ¡ lineÃ¡rna regresia rozÅ¡iruje jednoduchÃº regresiu na viac vstupnÃ½ch premennÃ½ch. UmoÅ¾Åˆuje lepÅ¡ie modelovaÅ¥ komplexnejÅ¡ie vzÅ¥ahy v dÃ¡tach.

### ğŸ“ Rovnica viacnÃ¡sobnej lineÃ¡rnej regresie

$$
y = wâ‚€ + wâ‚Â·xâ‚ + wâ‚‚Â·xâ‚‚ + â€¦ + wâ‚™Â·xâ‚™
$$

kde $$xâ‚...xâ‚™$$ sÃº vstupnÃ© atribÃºty a $$wâ‚...wâ‚™$$ ich koeficienty (vÃ¡hy/weights).

$$
y = Î²0 + Î²1 x1 + Î²2 x2 + â‹¯ + Î²n xn + Îµ
$$

kde $$xâ‚...xâ‚™$$ sÃº vstupnÃ© atribÃºty a $$wâ‚...wâ‚™$$ ich koeficienty (vÃ¡hy/weights).

â€¢  $$y$$ â€“ zÃ¡vislÃ¡ premennÃ¡ (predikovanÃ¡ hodnota)
â€¢  $$x_1, x_2, ..., x_n$$ â€“ nezÃ¡vislÃ© premennÃ© (vysvetÄ¾ujÃºce premennÃ©)
â€¢  $$Î²_0$$ â€“ intercept (konÅ¡tanta)
â€¢  $$Î²_1, Î²_2, ..., Î²_n$$ â€“ regresnÃ© koeficienty (vÃ¡hy premennÃ½ch)
â€¢  $$Îµ$$ â€“ nÃ¡hodnÃ¡ chyba (reziduÃ¡l)

PrÃ­klad pre 3 premennÃ©:
$$
y = Î²0 + Î²1 x1 + Î²2 x2 + Î²3 x3 + Îµ
$$
PouÅ¾Ã­va sa naprÃ­klad na predikciu cien, vÃ½nosov alebo skÃ³re na zÃ¡klade viacerÃ½ch vstupnÃ½ch faktorov.

---

### ğŸ§ª PrÃ­klad 1: TrÃ©ning viacnÃ¡sobnÃ©ho modelu so vÅ¡etkÃ½mi atribÃºtmi

```python
from sklearn.linear_model import LinearRegression

model_multi = LinearRegression()
model_multi.fit(X_train, y_train)

# Predikcia
y_pred = model_multi.predict(X_test)

# Vyhodnotenie
from sklearn.metrics import r2_score, mean_squared_error
print("R2:", r2_score(y_test, y_pred))
print("MSE:", mean_squared_error(y_test, y_pred))
```

---

### ğŸ§ª PrÃ­klad 2: NormalizÃ¡cia vstupov pomocou StandardScaler

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

model_scaled = LinearRegression()
model_scaled.fit(X_train_scaled, y_train)

# Predikcia a vyhodnotenie
y_pred_scaled = model_scaled.predict(X_test_scaled)
print("R2 (Å¡kÃ¡lovanÃ©):", r2_score(y_test, y_pred_scaled))
```

---

### ğŸ§ª PrÃ­klad 3: VÃ½ber najlepÅ¡Ã­ch atribÃºtov pomocou SelectKBest

```python
from sklearn.feature_selection import SelectKBest, f_regression

# Vyber 5 najrelevantnejÅ¡Ã­ch atribÃºtov
selector = SelectKBest(score_func=f_regression, k=5)
X_train_selected = selector.fit_transform(X_train_scaled, y_train)
X_test_selected = selector.transform(X_test_scaled)

model_kbest = LinearRegression()
model_kbest.fit(X_train_selected, y_train)
print("R2 (SelectKBest):", model_kbest.score(X_test_selected, y_test))
```

â¡ï¸ VÃ½ber atribÃºtov pomÃ¡ha znÃ­Å¾iÅ¥ zloÅ¾itosÅ¥ modelu, odstrÃ¡niÅ¥ Å¡um a zvÃ½Å¡iÅ¥ interpretovateÄ¾nosÅ¥.
â¡ï¸ NormalizÃ¡cia zaisÅ¥uje rovnakÃ© vÃ¡hovÃ© podmienky pre vÅ¡etky atribÃºty.
â¡ï¸ OdporÃºÄame testovaÅ¥ rÃ´zne kombinÃ¡cie atribÃºtov a porovnÃ¡vaÅ¥ metriky.


```python
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.feature_selection import SelectKBest, f_regression

# NormalizÃ¡cia vstupnÃ½ch Ãºdajov
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_train)

# VÃ½ber 5 najlepÅ¡Ã­ch atribÃºtov podÄ¾a korelÃ¡cie s cieÄ¾ovou premennou
selector = SelectKBest(score_func=f_regression, k=5)
X_selected = selector.fit_transform(X_scaled, y_train)

# TrÃ©ning viacnÃ¡sobnÃ©ho regresnÃ©ho modelu
model = LinearRegression()
model.fit(X_selected, y_train)

# Vyhodnotenie na testovacÃ­ch dÃ¡tach
X_test_scaled = scaler.transform(X_test)
X_test_selected = selector.transform(X_test_scaled)

preds = model.predict(X_test_selected)
print("R2 score:", r2_score(y_test, preds))
print("Mean Squared Error:", mean_squared_error(y_test, preds))
```

---

<a name="zdroje-a-literatura"></a>
## ğŸ“š Zdroje a literatÃºra k strojovÃ©mu uÄeniu a scikit-learn

### ğŸ“˜ Top knihy â€“ Anglicky

| NÃ¡zov | Autor | Popis |
|-------|-------|-------|
| Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow | AurÃ©lien GÃ©ron | NajkomplexnejÅ¡ia kniha pre ML v Pythone. Obsahuje teÃ³riu aj praktickÃ© prÃ­klady. |
| Python Machine Learning | Sebastian Raschka, Vahid Mirjalili | Kniha zameranÃ¡ na praktickÃº implementÃ¡ciu ML algoritmov v Pythone. |
| Introduction to Machine Learning with Python | Andreas MÃ¼ller, Sarah Guido | VÃ½bornÃ½ Ãºvod do ML so zameranÃ­m na scikit-learn. |
| Machine Learning Yearning | Andrew Ng | StrategickÃ½ pohÄ¾ad na budovanie ML systÃ©mov (voÄ¾ne dostupnÃ© PDF). |
| Pattern Recognition and Machine Learning | Christopher Bishop | HlbÅ¡ie teoretickÃ© zÃ¡klady ML. |
| Data Science from Scratch | Joel Grus | ZÃ¡klady ML s implementÃ¡ciou algoritmov "od nuly". |

### ğŸ“™ Knihy a zdroje â€“ ÄŒesky a Slovensky

| NÃ¡zov | Autor | Popis |
|-------|-------|-------|
| UÄÃ­me se strojovÃ© uÄenÃ­ | OndÅ™ej VaÅˆo | ÄŒeskÃ¡ prÃ­ruÄka s praktickÃ½mi Ãºlohami v Pythone. |
| ZÃ¡klady strojovÃ©ho uÄenia | kol. autorov | Ãšvod do ML a zÃ¡kladnÃ© modely v ÄeÅ¡tine. |
| Python pro analÃ½zu dat | Wes McKinney (CZ preklad) | ZameranÃ© na prÃ¡cu s dÃ¡tami v Pandas, vhodnÃ© ako zÃ¡klad pre ML. |
| StrojovÃ© uÄenie v Pythone | Miroslav Reiter | PraktickÃ½ kurz pre zaÄiatoÄnÃ­kov s dÃ´razom na regresiu a scikit-learn. |

> ğŸ§  PoznÃ¡mka: ÄŒeskoslovenskÃ© tituly sÃº Äasto pre zaÄiatoÄnÃ­kov a pomÃ¡hajÃº pochopiÅ¥ zÃ¡klady v rodnom jazyku.

### ğŸŒ OficiÃ¡lna dokumentÃ¡cia a online zdroje

| NÃ¡zov | Popis | Odkaz |
|-------|--------|--------|
| scikit-learn User Guide | OficiÃ¡lna dokumentÃ¡cia a prÃ­ruÄky | [scikit-learn.org](https://scikit-learn.org/stable/user_guide.html) |
| scikit-learn API Reference | DetailnÃ© API popisy tried a funkciÃ­ | [scikit-learn.org API](https://scikit-learn.org/stable/modules/classes.html) |
| sklearn-examples GitHub | PrÃ­klady projektov s pouÅ¾itÃ­m scikit-learn | [github.com/scikit-learn](https://github.com/scikit-learn/scikit-learn) |
| Kaggle Learn ML | Online micro-kurzy a sÃºÅ¥aÅ¾e | [kaggle.com/learn](https://www.kaggle.com/learn/intro-to-machine-learning) |
| Machine Learning Mastery | Blog a nÃ¡vody pre praktickÃ© ML | [machinelearningmastery.com](https://machinelearningmastery.com) |
| Google AI Hub | NÃ¡stroje, datasetovÃ© repozitÃ¡re a prÃ­klady | [ai.google](https://ai.google/tools/) |
| Towards Data Science | Blogy a tutoriÃ¡ly od expertov z ML komunity | [towardsdatascience.com](https://towardsdatascience.com) |

---
<a name="odporucania"></a>
## âœ… OdporÃºÄania ML, regresia a Scikit-Learn

- ğŸ“¦ PouÅ¾i `pip install scikit-learn pandas matplotlib` na inÅ¡talÃ¡ciu
- ğŸ§ª Pracuj v prostredÃ­ Jupyter Notebook (napr. Jetbrains Datalore, VS Code, Google Colab)
- ğŸ’¾ PouÅ¾Ã­vaj `.fit()` na uÄenie modelu a `.predict()` na predikciu novÃ½ch vstupov
- ğŸ” VyuÅ¾Ã­vaj `train_test_split()` na oddelenie trÃ©ningovÃ½ch a testovacÃ­ch dÃ¡t
- ğŸ›  SkÃºÅ¡aj rÃ´zne metriky vÃ½konu (napr. RÂ², MSE, MAE) podÄ¾a typu Ãºlohy
- ğŸ“Š Vizualizuj vÃ½sledky cez `matplotlib` alebo `seaborn` pre lepÅ¡ie porozumenie dÃ¡t
- ğŸ§  Pri vÃ½bere atribÃºtov pouÅ¾i `SelectKBest`, `RFE` alebo `feature_importances_`
- ğŸ” PouÅ¾Ã­vaj `cross_val_score()` na krÃ­Å¾ovÃº validÃ¡ciu modelu
- ğŸ§ª Nezabudni na `StandardScaler()` alebo `MinMaxScaler()` pri Å¡kÃ¡lovanÃ­ Ãºdajov
- ğŸ—ƒï¸ Na prÃ¡cu s vÃ¤ÄÅ¡Ã­mi datasetmi vyskÃºÅ¡aj `fetch_california_housing` alebo vlastnÃ© CSV sÃºbory
- ğŸ§¾ Sleduj novinky na [scikit-learn release log](https://scikit-learn.org/stable/whats_new.html) pre novÃ© funkcie a zmeny

---

