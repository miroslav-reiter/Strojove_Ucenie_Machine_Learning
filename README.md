# ğŸ¤– Online kurz: StrojovÃ© uÄenie (Machine Learning) v Pythone so scikit-learn

> PraktickÃ½ kurz pre zaÄiatoÄnÃ­kov â€“ Regresia v ML, scikit-learn, modelovanie, trÃ©ning a vyhodnocovanie

---

## ğŸ“˜ Obsah kurzu

01. [**ğŸ” Ãšvod do strojovÃ©ho uÄenia a regresie**](#uvod-ml-regresia)  
02. [**ğŸ“ˆ LineÃ¡rna regresia v scikit-learn**](#linearna-regresia)  
03. [**ğŸ§® ViacnÃ¡sobnÃ¡ regresia a vÃ½ber premennÃ½ch**](#viacnasobna-regresia)

---

<a name="uvod-ml-regresia"></a>
## ğŸ” 1. Ãšvod do strojovÃ©ho uÄenia a regresie

V tejto Ãºvodnej Äasti sa zoznÃ¡mime so zÃ¡kladnÃ½mi pojmami, rozdielmi medzi typmi ML Ãºloh, kniÅ¾nicou scikit-learn a jednoduchÃ½mi praktickÃ½mi prÃ­kladmi.

### ğŸ¯ ZÃ¡kladnÃ© pojmy

- **Supervised learning (uÄenie s uÄiteÄ¾om)** â€“ algoritmus sa uÄÃ­ na zÃ¡klade oznaÄenÃ½ch dÃ¡t (X vstupy, y vÃ½stupy)
- **Training (trÃ©ning)** â€“ fÃ¡za uÄenia modelu na zÃ¡klade historickÃ½ch Ãºdajov
- **Testing (testovanie)** â€“ overenie vÃ½konu modelu na novÃ½ch Ãºdajoch, ktorÃ© nevidel
- **Regresia vs. klasifikÃ¡cia**:
  - *Regresia* predpovedÃ¡ **spojitÃ© hodnoty** (napr. cena, teplota)
  - *KlasifikÃ¡cia* predpovedÃ¡ **kategÃ³rie** (napr. Ã¡no/nie, trieda A/B/C)

### ğŸ§© Typy regresiÃ­ (prehÄ¾ad)

- **JednoduchÃ¡ lineÃ¡rna regresia** â€“ 1 vstupnÃ¡ premennÃ¡ (napr. vÃ½Å¡ka â†’ hmotnosÅ¥)
- **ViacnÃ¡sobnÃ¡ lineÃ¡rna regresia** â€“ viac vstupov (napr. vÃ½Å¡ka, vek, BMI â†’ hmotnosÅ¥)
- **PolynomiÃ¡lna regresia** â€“ rozÅ¡Ã­renie lineÃ¡rnej pomocou nelineÃ¡rnych zloÅ¾iek

---

### ğŸ§ª PrÃ­klad 1: NaÄÃ­tanie dÃ¡t a zÃ¡kladnÃ¡ Å¡tatistika

```python
from sklearn.datasets import load_diabetes
import pandas as pd

# NaÄÃ­tanie datasetu (zabudovanÃ½ dataset s Ãºdajmi o cukrovke)
data = load_diabetes(as_frame=True)
df = data.frame

# Zobrazenie prvÃ½ch 5 riadkov
print(df.head())

# ZÃ¡kladnÃ¡ Å¡tatistika
print(df.describe())
```

---

### ğŸ§ª PrÃ­klad 2: Rozdelenie dÃ¡t na trÃ©ningovÃº a testovaciu mnoÅ¾inu

```python
from sklearn.model_selection import train_test_split

X = df.drop(columns='target')  # vstupy (atribÃºty)
y = df['target']               # cieÄ¾ovÃ¡ premennÃ¡

# Rozdelenie na 80 % trÃ©ning a 20 % test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("TrÃ©ningovÃ¡ mnoÅ¾ina:", X_train.shape)
print("Testovacia mnoÅ¾ina:", X_test.shape)
```

---

### ğŸ§ª PrÃ­klad 3: ZÃ¡kladnÃ¡ vizualizÃ¡cia vzÅ¥ahu medzi atribÃºtom a cieÄ¾om

```python
import matplotlib.pyplot as plt

# Porovnanie BMI a cieÄ¾ovej hodnoty
plt.scatter(X['bmi'], y, color='green', alpha=0.5)
plt.xlabel('BMI')
plt.ylabel('CieÄ¾ovÃ¡ premennÃ¡ (target)')
plt.title('VzÅ¥ah medzi BMI a cieÄ¾om')
plt.grid(True)
plt.show()
```

---

### ğŸ§ª PrÃ­klad 4: PrehÄ¾ad funkciÃ­ kniÅ¾nice scikit-learn

```python
import sklearn

# Verzia kniÅ¾nice
print("scikit-learn verzia:", sklearn.__version__)

# Skontroluj dostupnÃ© moduly: linear_model, model_selection, metrics...
from sklearn import linear_model, metrics, preprocessing
print(dir(linear_model))  # dostupnÃ© modely v linear_model
```

TÃ½mto sme zÃ­skali zÃ¡kladnÃ½ prehÄ¾ad o tom:
- ako vyzerajÃº dÃ¡ta,
- ako sa rozdeÄ¾ujÃº na trÃ©ning a test,
- ako vizualizovaÅ¥ vzÅ¥ahy a
- Äo ponÃºka kniÅ¾nica scikit-learn.

```python
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
import pandas as pd

# NaÄÃ­tanie vstupnÃ©ho datasetu diabetes
X, y = load_diabetes(return_X_y=True, as_frame=True)

# Rozdelenie na trÃ©ningovÃº a testovaciu mnoÅ¾inu (80:20)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# VÃ½pis tvaru datasetu
print(X_train.shape, X_test.shape)
```

---

<a name="linearna-regresia"></a>
## ğŸ“ˆ 2. LineÃ¡rna regresia v scikit-learn

LineÃ¡rna regresia je zÃ¡kladnÃ½ model na predikciu spojitÃ½ch hodnÃ´t. Jej cieÄ¾om je nÃ¡jsÅ¥ optimÃ¡lnu priamku (alebo hyperrovinu), ktorÃ¡ minimalizuje chybu medzi predikovanÃ½mi a skutoÄnÃ½mi hodnotami.

### ğŸ“ Rovnica lineÃ¡rnej regresie

$$
y = w_0 + w_1 x_1 + w_2 x_2 + \dots + w_n x_n
$$


kde $$w_i \)$$  sÃº koeficienty modelu a $$( x_i \)$$  vstupnÃ© premennÃ©.

---

### ğŸ§ª PrÃ­klad 1: JednoduchÃ¡ lineÃ¡rna regresia (1 vstup)

```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error

# Vytvorenie modelu a natrÃ©novanie na jednom atribÃºte (napr. BMI)
model = LinearRegression()
model.fit(X_train[['bmi']], y_train)

# Predikcia hodnÃ´t na testovacej mnoÅ¾ine
preds = model.predict(X_test[['bmi']])

# Vyhodnotenie modelu
print("R2 score:", r2_score(y_test, preds))
print("MSE:", mean_squared_error(y_test, preds))
```

---

### ğŸ§ª PrÃ­klad 2: VizualizÃ¡cia regresnej priamky

```python
import matplotlib.pyplot as plt

# SkutoÄnÃ© vs. predikovanÃ© hodnoty
plt.scatter(X_test['bmi'], y_test, color='gray', label='SkutoÄnÃ©')
plt.plot(X_test['bmi'], preds, color='red', label='PredikovanÃ©')
plt.xlabel('BMI')
plt.ylabel('CieÄ¾ovÃ¡ premennÃ¡')
plt.title('LineÃ¡rna regresia: BMI vs. cieÄ¾')
plt.legend()
plt.show()
```

---

### ğŸ§ª PrÃ­klad 3: Zobrazenie koeficientov modelu

```python
# Koeficient (sklon priamky)
print("Koeficient w1:", model.coef_[0])

# AbsolÃºtna hodnota intercept (posun priamky)
print("Intercept w0:", model.intercept_)
```

---

### ğŸ§ª PrÃ­klad 4: Viac atribÃºtov naraz â€“ multivariaÄnÃ¡ lineÃ¡rna regresia

```python
# VÅ¡etky atribÃºty pouÅ¾itÃ© na trÃ©ning
model_multi = LinearRegression()
model_multi.fit(X_train, y_train)

# Predikcia a vyhodnotenie
preds_multi = model_multi.predict(X_test)
print("R2 (viac atribÃºtov):", r2_score(y_test, preds_multi))
```


```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
import matplotlib.pyplot as plt

# TrÃ©ning modelu na jednom atribÃºte (napr. BMI)
model = LinearRegression()
model.fit(X_train[['bmi']], y_train)

# Predikcia hodnÃ´t
preds = model.predict(X_test[['bmi']])

# Vyhodnotenie vÃ½konu modelu
print("R2 score:", r2_score(y_test, preds))
print("Mean Squared Error:", mean_squared_error(y_test, preds))

# VizualizÃ¡cia
plt.scatter(X_test['bmi'], y_test, color='blue', label='SkutoÄnÃ© hodnoty')
plt.plot(X_test['bmi'], preds, color='red', label='PredikovanÃ© hodnoty')
plt.xlabel('BMI')
plt.ylabel('CieÄ¾ovÃ¡ hodnota')
plt.title('LineÃ¡rna regresia na BMI')
plt.legend()
plt.show()
```

---

<a name="viacnasobna-regresia"></a>
## ğŸ§® 3. ViacnÃ¡sobnÃ¡ regresia a vÃ½ber premennÃ½ch

- Vysvetlenie konceptu: viacero vstupov (features)
- NormalizÃ¡cia: `StandardScaler`
- VÃ½ber relevantnÃ½ch premennÃ½ch: `SelectKBest`, `RFE`, `feature_importances_`
- ViacnÃ¡sobnÃ¡ regresia v scikit-learn

```python
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.feature_selection import SelectKBest, f_regression

# NormalizÃ¡cia vstupnÃ½ch Ãºdajov
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_train)

# VÃ½ber 5 najlepÅ¡Ã­ch atribÃºtov podÄ¾a korelÃ¡cie s cieÄ¾ovou premennou
selector = SelectKBest(score_func=f_regression, k=5)
X_selected = selector.fit_transform(X_scaled, y_train)

# TrÃ©ning viacnÃ¡sobnÃ©ho regresnÃ©ho modelu
model = LinearRegression()
model.fit(X_selected, y_train)

# Vyhodnotenie na testovacÃ­ch dÃ¡tach
X_test_scaled = scaler.transform(X_test)
X_test_selected = selector.transform(X_test_scaled)

preds = model.predict(X_test_selected)
print("R2 score:", r2_score(y_test, preds))
print("Mean Squared Error:", mean_squared_error(y_test, preds))
```

---

## ğŸ“š Zdroje a literatÃºra k strojovÃ©mu uÄeniu a scikit-learn

### ğŸ“˜ Top knihy â€“ Anglicky

| NÃ¡zov | Autor | Popis |
|-------|-------|-------|
| Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow | AurÃ©lien GÃ©ron | NajkomplexnejÅ¡ia kniha pre ML v Pythone. Obsahuje teÃ³riu aj praktickÃ© prÃ­klady. |
| Python Machine Learning | Sebastian Raschka, Vahid Mirjalili | Kniha zameranÃ¡ na praktickÃº implementÃ¡ciu ML algoritmov v Pythone. |
| Introduction to Machine Learning with Python | Andreas MÃ¼ller, Sarah Guido | VÃ½bornÃ½ Ãºvod do ML so zameranÃ­m na scikit-learn. |
| Machine Learning Yearning | Andrew Ng | StrategickÃ½ pohÄ¾ad na budovanie ML systÃ©mov (voÄ¾ne dostupnÃ© PDF). |
| Pattern Recognition and Machine Learning | Christopher Bishop | HlbÅ¡ie teoretickÃ© zÃ¡klady ML. |
| Data Science from Scratch | Joel Grus | ZÃ¡klady ML s implementÃ¡ciou algoritmov "od nuly". |

### ğŸ“™ Knihy a zdroje â€“ ÄŒesky a Slovensky

| NÃ¡zov | Autor | Popis |
|-------|-------|-------|
| UÄÃ­me se strojovÃ© uÄenÃ­ | OndÅ™ej VaÅˆo | ÄŒeskÃ¡ prÃ­ruÄka s praktickÃ½mi Ãºlohami v Pythone. |
| ZÃ¡klady strojovÃ©ho uÄenia | kol. autorov | Ãšvod do ML a zÃ¡kladnÃ© modely v ÄeÅ¡tine. |
| Python pro analÃ½zu dat | Wes McKinney (CZ preklad) | ZameranÃ© na prÃ¡cu s dÃ¡tami v Pandas, vhodnÃ© ako zÃ¡klad pre ML. |
| StrojovÃ© uÄenie v Pythone | Miroslav Reiter | PraktickÃ½ kurz pre zaÄiatoÄnÃ­kov s dÃ´razom na regresiu a scikit-learn. |

> ğŸ§  PoznÃ¡mka: ÄŒeskoslovenskÃ© tituly sÃº Äasto pre zaÄiatoÄnÃ­kov a pomÃ¡hajÃº pochopiÅ¥ zÃ¡klady v rodnom jazyku.

### ğŸŒ OficiÃ¡lna dokumentÃ¡cia a online zdroje

| NÃ¡zov | Popis | Odkaz |
|-------|--------|--------|
| scikit-learn User Guide | OficiÃ¡lna dokumentÃ¡cia a prÃ­ruÄky | [scikit-learn.org](https://scikit-learn.org/stable/user_guide.html) |
| scikit-learn API Reference | DetailnÃ© API popisy tried a funkciÃ­ | [scikit-learn.org API](https://scikit-learn.org/stable/modules/classes.html) |
| sklearn-examples GitHub | PrÃ­klady projektov s pouÅ¾itÃ­m scikit-learn | [github.com/scikit-learn](https://github.com/scikit-learn/scikit-learn) |
| Kaggle Learn ML | Online micro-kurzy a sÃºÅ¥aÅ¾e | [kaggle.com/learn](https://www.kaggle.com/learn/intro-to-machine-learning) |
| Machine Learning Mastery | Blog a nÃ¡vody pre praktickÃ© ML | [machinelearningmastery.com](https://machinelearningmastery.com) |
| Google AI Hub | NÃ¡stroje, datasetovÃ© repozitÃ¡re a prÃ­klady | [ai.google](https://ai.google/tools/) |
| Towards Data Science | Blogy a tutoriÃ¡ly od expertov z ML komunity | [towardsdatascience.com](https://towardsdatascience.com) |

---

## âœ… OdporÃºÄania

- ğŸ“¦ PouÅ¾i `pip install scikit-learn pandas matplotlib` na inÅ¡talÃ¡ciu
- ğŸ§ª Pracuj v prostredÃ­ Jupyter Notebook (napr. Jetbrains Datalore, VS Code, Google Colab)
- ğŸ’¾ PouÅ¾Ã­vaj `.fit()` na uÄenie modelu a `.predict()` na predikciu novÃ½ch vstupov
- ğŸ” VyuÅ¾Ã­vaj `train_test_split()` na oddelenie trÃ©ningovÃ½ch a testovacÃ­ch dÃ¡t
- ğŸ›  SkÃºÅ¡aj rÃ´zne metriky vÃ½konu (napr. RÂ², MSE, MAE) podÄ¾a typu Ãºlohy
- ğŸ“Š Vizualizuj vÃ½sledky cez `matplotlib` alebo `seaborn` pre lepÅ¡ie porozumenie dÃ¡t
- ğŸ§  Pri vÃ½bere atribÃºtov pouÅ¾i `SelectKBest`, `RFE` alebo `feature_importances_`
- ğŸ” PouÅ¾Ã­vaj `cross_val_score()` na krÃ­Å¾ovÃº validÃ¡ciu modelu
- ğŸ§ª Nezabudni na `StandardScaler()` alebo `MinMaxScaler()` pri Å¡kÃ¡lovanÃ­ Ãºdajov
- ğŸ—ƒï¸ Na prÃ¡cu s vÃ¤ÄÅ¡Ã­mi datasetmi vyskÃºÅ¡aj `fetch_california_housing` alebo vlastnÃ© CSV sÃºbory
- ğŸ§¾ Sleduj novinky na [scikit-learn release log](https://scikit-learn.org/stable/whats_new.html) pre novÃ© funkcie a zmeny

---

